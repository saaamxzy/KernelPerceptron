{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "## Problem 1.1\n",
    "Training error for normal perceptron: 0.04036697247706422 (after 2 passes).\n",
    "\n",
    "\n",
    "Test error for normal perceptron: 0.0610079575596817. (after 2 passes)\n",
    "\n",
    "\n",
    "Training error for voted perceptron: 0.04128440366972477 (after 2 passes).\n",
    "\n",
    "\n",
    "Test error for voted perceptron: 0.0610079575596817. (after 2 passes)\n",
    "\n",
    "\n",
    "Training error for average perceptron: 0.05412844036697248. (after 2 passes)\n",
    "\n",
    "\n",
    "Test error for average perceptron: 0.08222811671087533. (after 2 passes)\n",
    "\n",
    "-----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "Training error for normal perceptron: 0.02110091743119266 (after 3 passes).\n",
    "\n",
    "\n",
    "Test error for normal perceptron: 0.04509283819628647. (after 3 passes)\n",
    "\n",
    "\n",
    "Training error for voted perceptron: 0.030275229357798167 (after 3 passes).\n",
    "\n",
    "\n",
    "Test error for voted perceptron: 0.04509283819628647. (after 3 passes)\n",
    "\n",
    "\n",
    "Training error for average perceptron: 0.03486238532110092. (after 3 passes)\n",
    "\n",
    "\n",
    "Test error for average perceptron: 0.0610079575596817. (after 3 passes)\n",
    "\n",
    "-----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "Training error for normal perceptron: 0.01926605504587156 (after 4 passes).\n",
    "\n",
    "\n",
    "Test error for normal perceptron: 0.04774535809018567. (after 4 passes)\n",
    "\n",
    "\n",
    "Training error for voted perceptron: 0.025688073394495414 (after 4 passes).\n",
    "\n",
    "\n",
    "Test error for voted perceptron: 0.04509283819628647. (after 4 passes)\n",
    "\n",
    "\n",
    "Training error for average perceptron: 0.031192660550458717. (after 4 passes)\n",
    "\n",
    "\n",
    "Test error for average perceptron: 0.050397877984084884. (after 4 passes)\n",
    "\n",
    "-----------------------------------------------------------------------\n",
    "\n",
    "## Problem 1.2\n",
    "\n",
    "The three highest coordinates in Wavg are (Dictionary Index, Value) : (439, 117371.0), (467, 72270.0), (204, 45353.0)\n",
    "\n",
    "\n",
    "Corresponding wors are \"file\", \"program\" and \"line\"\n",
    "\n",
    "\n",
    "The three lowest coordinates in Wavg are (Dictionary Index, Value) : (79, -294511.0), (470, -164072.0), (394, -153026.0\n",
    "\n",
    "\n",
    "Corresponding wors are \"he\", \"team\" and \"game\"\n",
    "\n",
    "-----------------------------------------------------------------------\n",
    "\n",
    "## Problem 1.3\n",
    "\n",
    "![Confusion Matrix](./img/confusion_mat.png)\n",
    "\n",
    "(a) Label 5 has the highest accuracy.\n",
    "(b) Label 3 has the lowest accuracy.\n",
    "(c) The perceptron classifier most often mistakenly classifies an example in class 6 belonging to class 5.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "        f = open(filename,'r')\n",
    "        ls = []\n",
    "        ls_label = [list() for _ in range(6)]\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            content = [int(x) for x in line.strip().split()]\n",
    "            ls.append(content)\n",
    "            label = content[-1]\n",
    "            ls_label[label-1].append(content)\n",
    "        f.close()\n",
    "\n",
    "        return np.asarray(ls), ls_label\n",
    "    \n",
    "    \n",
    "def get_data_set_sequential(c1, c2, train_all):\n",
    "    rs = []\n",
    "    for data in train_all:\n",
    "        if data[-1] == c1:\n",
    "            data[-1] = 1\n",
    "            rs.append(data)\n",
    "        elif data[-1] == c2:\n",
    "            data[-1] = -1\n",
    "            rs.append(data)\n",
    "    return np.asarray(rs)\n",
    "\n",
    "def get_data_multi(c, train_all):\n",
    "    rs = []\n",
    "    \n",
    "    for data in train_all:\n",
    "        if data[-1] == c:\n",
    "            data[-1] = 1\n",
    "        else:\n",
    "            data[-1] = -1\n",
    "        rs.append(data)\n",
    "    return np.asarray(rs)\n",
    "    \n",
    "def get_data_set(c1, c2, ls_label):\n",
    "    c1_train = np.asarray(ls_label[c1-1])\n",
    "    c2_train = np.asarray(ls_label[c2-1])\n",
    "    c1_train[:,-1] = 1\n",
    "    c2_train[:,-1] = -1\n",
    "    train_data = np.asarray(np.vstack((c1_train, c2_train)))\n",
    "    np.random.shuffle(train_data)\n",
    "    return train_data\n",
    "    \n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, train_all):\n",
    "        self.train = train_all\n",
    "        self.w = np.zeros(self.train.shape[1]-1)\n",
    "    \n",
    "        \n",
    "    def train_normal(self, t):\n",
    "        for i in range(t):\n",
    "            for data in self.train:\n",
    "                y = data[-1]\n",
    "                x = data[:-1]\n",
    "                if y * np.dot(self.w, x) <= 0:\n",
    "                    self.w = self.w + y * x\n",
    "                    \n",
    "    def train_voted(self, t):\n",
    "        self.counts = defaultdict(tuple)\n",
    "        w = np.zeros(self.train.shape[1]-1)\n",
    "        m = 1\n",
    "        cm = 1\n",
    "        self.counts[m] = (w, cm)\n",
    "        \n",
    "        \n",
    "        for i in range(t):\n",
    "\n",
    "            w = self.w\n",
    "            for data in self.train:\n",
    "                y = data[-1]\n",
    "                x = data[:-1]\n",
    "                if y * np.dot(w, x) <= 0:\n",
    "                    self.counts[m] = (w, cm)\n",
    "                    w = w + y * x\n",
    "                    m += 1\n",
    "                    cm = 1\n",
    "                else:\n",
    "                    cm += 1\n",
    "            self.w = w\n",
    "            \n",
    "    def train_average(self, t):\n",
    "        self.counts = defaultdict(tuple)\n",
    "        w = np.zeros(self.train.shape[1]-1)\n",
    "        m = 1\n",
    "        cm = 1\n",
    "        self.counts[m] = (w, cm)\n",
    "        \n",
    "        self.w_sum = np.zeros(self.train.shape[1]-1)\n",
    "        \n",
    "        for i in range(t):\n",
    "\n",
    "            w = self.w\n",
    "            for data in self.train:\n",
    "                y = data[-1]\n",
    "                x = data[:-1]\n",
    "                if y * np.dot(w, x) <= 0:\n",
    "                    self.counts[m] = (w, cm)\n",
    "                    self.w_sum += cm * w\n",
    "                    w = w + y * x\n",
    "                    m += 1\n",
    "                    cm = 1\n",
    "                else:\n",
    "                    cm += 1\n",
    "            self.w = w\n",
    "        \n",
    "    def evaluate_average(self, eval_data):\n",
    "        eval_x = eval_data[:,:-1]\n",
    "        eval_y = eval_data[:,-1]\n",
    "        \n",
    "        predictions = np.dot(eval_x, self.w_sum)\n",
    "        assert eval_y.shape == predictions.shape, 'number of labels mismatch.'\n",
    "        rs = np.where(predictions > 0, 1, -1)\n",
    "        rs[np.where(predictions == 0)] = random.choice([0,1])\n",
    "        return float(np.count_nonzero(eval_y - rs)) / eval_data.shape[0]\n",
    "                                        \n",
    "    def predict_voted(self, x):\n",
    "        prediction = 0\n",
    "        for m, (w, c) in self.counts.items():\n",
    "            rs = np.dot(w, x)\n",
    "            if rs > 0:\n",
    "                prediction += c\n",
    "            elif rs < 0:\n",
    "                prediction -= c\n",
    "        \n",
    "        return 1 if prediction > 0 else -1\n",
    "    \n",
    "    def evaluate_voted(self, eval_data):\n",
    "        eval_x = eval_data[:,:-1]\n",
    "        eval_y = eval_data[:,-1]\n",
    "        \n",
    "        error = 0\n",
    "        for data in eval_data:\n",
    "            prediction = self.predict_voted(data[:-1])\n",
    "            if prediction != data[-1]:\n",
    "                error+=1\n",
    "                \n",
    "        return float(error) / eval_data.shape[0]\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return 1 if np.dot(x, self.w) > 0 else -1\n",
    "        \n",
    "    def predict_average(self, x):\n",
    "        return 1 if np.dot(x, self.w_sum) > 0 else -1\n",
    "    \n",
    "    def evaluate(self, eval_data):\n",
    "        eval_x = eval_data[:,:-1]\n",
    "        eval_y = eval_data[:,-1]\n",
    "        \n",
    "        predictions = np.dot(eval_x, self.w)\n",
    "        assert eval_y.shape == predictions.shape, 'number of labels mismatch.'\n",
    "        rs = np.where(predictions > 0, 1, -1)\n",
    "        rs[np.where(predictions == 0)] = random.choice([0,1])\n",
    "        return float(np.count_nonzero(eval_y - rs)) / eval_data.shape[0]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.w = np.zeros(self.train.shape[1]-1)\n",
    "        \n",
    "    def get_w_sum(self):\n",
    "        return self.w_sum\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension of all train data: (3000, 820).\n",
      "Training error for normal perceptron: 0.04128440366972477 (after 1 passes).\n",
      "Test error for normal perceptron: 0.05305039787798409. (after 1 passes)\n",
      "\n",
      "Training error for voted perceptron: 0.06788990825688074 (after 1 passes).\n",
      "Test error for voted perceptron: 0.08753315649867374. (after 1 passes)\n",
      "\n",
      "Training error for average perceptron: 0.0798165137614679. (after 1 passes)\n",
      "Test error for average perceptron: 0.11671087533156499. (after 1 passes)\n"
     ]
    }
   ],
   "source": [
    "# Problem 1.1\n",
    "\n",
    "train_all, train_separate = read_file('./data/pa3train.txt')\n",
    "test_all, test_separate = read_file('./data/pa3test.txt')\n",
    "\n",
    "times = 1\n",
    "passes = 1\n",
    "\n",
    "print('dimension of all train data: {}.'.format(train_all.shape))\n",
    "#print('dimension of separate train data: {}.'.format(train_separate.shape))\n",
    "train_data_seq = get_data_set_sequential(1,2,train_all)\n",
    "train_data = get_data_set(1,2, train_separate)\n",
    "test_data = get_data_set(1,2, test_separate)\n",
    "\n",
    "\n",
    "# Normal Perceptron\n",
    "p1 = Perceptron(train_data_seq)\n",
    "\n",
    "p1.train_normal(passes)\n",
    "\n",
    "train_error = p1.evaluate(train_data)\n",
    "print('Training error for normal perceptron: {} (after {} passes).'.format(train_error, passes))\n",
    "\n",
    "test_error = p1.evaluate(test_data)\n",
    "print('Test error for normal perceptron: {}. (after {} passes)'.format(test_error, passes))\n",
    "\n",
    "# Used only for shuffled data. Not useful for this grading\n",
    "\n",
    "# train_error = 0.0\n",
    "# for i in range(times):\n",
    "#     train_error += p1.evaluate(train_data)\n",
    "# train_error /= times\n",
    "# print('The average training error is: {} (after running {} times).'.format(train_error, times))\n",
    "\n",
    "\n",
    "# test_error = 0.0\n",
    "# for i in range(times):\n",
    "#     test_error += p1.evaluate(test_data)\n",
    "# test_error /= times\n",
    "# print('The average test error is: {} (after running {} times).'.format(test_error, times))\n",
    "\n",
    "print()\n",
    "\n",
    "# Voted Perceptron\n",
    "p2 = Perceptron(train_data_seq)\n",
    "\n",
    "p2.train_voted(passes)\n",
    "\n",
    "train_error = p2.evaluate_voted(train_data)\n",
    "print('Training error for voted perceptron: {} (after {} passes).'.format(train_error, passes))\n",
    "\n",
    "test_error = p2.evaluate_voted(test_data)\n",
    "print('Test error for voted perceptron: {}. (after {} passes)'.format(test_error, passes))\n",
    "\n",
    "print()\n",
    "\n",
    "# Average Perceptron\n",
    "\n",
    "p3 = Perceptron(train_data_seq)\n",
    "\n",
    "p3.train_average(passes)\n",
    "\n",
    "train_error = p3.evaluate_average(train_data)\n",
    "print('Training error for average perceptron: {}. (after {} passes)'.format(train_error, passes))\n",
    "\n",
    "test_error = p3.evaluate_average(test_data)\n",
    "print('Test error for average perceptron: {}. (after {} passes)'.format(test_error, passes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(439, 117371.0)\n",
      "(467, 72270.0)\n",
      "(204, 45353.0)\n",
      "(79, -71608.0)\n",
      "(470, -35978.0)\n",
      "(142, -34471.0)\n"
     ]
    }
   ],
   "source": [
    "# Problem 1.2\n",
    "\n",
    "w_avg = p3.get_w_sum()\n",
    "\n",
    "rs = []\n",
    "\n",
    "for i,each in enumerate(list(w_avg)):\n",
    "    rs.append((i+1, each))\n",
    "sorted_rs = sorted(rs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i in range(3):\n",
    "    print(sorted_rs[i])\n",
    "    \n",
    "reverse_sorted_rs = sorted_rs[::-1]\n",
    "\n",
    "for i in range(3):\n",
    "    print(reverse_sorted_rs[i])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "[[ 0.71891892  0.00520833  0.03428571  0.02173913  0.          0.        ]\n",
      " [ 0.01081081  0.65625     0.03428571  0.02717391  0.01282051  0.01851852]\n",
      " [ 0.          0.015625    0.37142857  0.          0.          0.02777778]\n",
      " [ 0.01621622  0.00520833  0.          0.69021739  0.          0.        ]\n",
      " [ 0.01621622  0.03125     0.07428571  0.00543478  0.80128205  0.12037037]\n",
      " [ 0.00540541  0.01041667  0.03428571  0.          0.07051282  0.49074074]\n",
      " [ 0.23243243  0.27604167  0.45142857  0.25543478  0.11538462  0.34259259]]\n"
     ]
    }
   ],
   "source": [
    "# Problem 1.3\n",
    "confusion_mat = np.zeros((7,6))\n",
    "train_all, _ = read_file('./data/pa3train.txt')\n",
    "plist = []\n",
    "for i in range(6):\n",
    "    train_data = get_data_multi(i+1, deepcopy(train_all))\n",
    "    p = Perceptron(train_data)\n",
    "    p.train_normal(1)\n",
    "    plist.append(p)\n",
    "\n",
    "    \n",
    "# for data in plist[1].train:\n",
    "#     print(data[-1])\n",
    "#print(plist[1].train)\n",
    "    \n",
    "# for data in train_data:    \n",
    "#     print(plist[1].predict(data[:-1]))\n",
    "\n",
    "    \n",
    "    \n",
    "N = defaultdict(int)\n",
    "C = defaultdict(int)\n",
    "\n",
    "for j in test_all[:,-1]:\n",
    "    N[j] += 1\n",
    "    \n",
    "result = []\n",
    "for data in test_all:\n",
    "    test_x = data[:-1]\n",
    "    test_y = data[-1]\n",
    "    predictions = []\n",
    "    for p in plist:\n",
    "        predictions.append(p.predict(test_x))\n",
    "    \n",
    "    #print(predictions)\n",
    "    if predictions.count(1) > 1:\n",
    "        predictions = 7\n",
    "    elif predictions.count(1) == 0:\n",
    "        predictions = 7\n",
    "    elif predictions.count(1) == 1:\n",
    "        predictions = predictions.index(1) + 1\n",
    "        \n",
    "    #if predictions != test_y:\n",
    "    C[(predictions, test_y)] += 1\n",
    "    result.append(predictions)\n",
    "    \n",
    "result = np.asarray(result)\n",
    "#print(result, test_all[:,-1])\n",
    "\n",
    "for i in range(confusion_mat.shape[0]):\n",
    "    for j in range(confusion_mat.shape[1]):\n",
    "        confusion_mat[i][j] = float(C[(i+1,j+1)]) / float(N[j+1])\n",
    "                            \n",
    "print('Confusion matrix: ')                             \n",
    "print(confusion_mat)\n",
    "#print(len(plist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
